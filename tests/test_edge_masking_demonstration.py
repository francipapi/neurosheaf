#!/usr/bin/env python3
"""
Demonstration test for the new mathematically correct edge masking system.

This test showcases the key improvements in the unified static Laplacian 
implementation with proper block reconstruction vs the old entry-zeroing approach.
"""

import torch
import numpy as np
import networkx as nx
import time
import sys

sys.path.insert(0, '/Users/francescopapini/GitRepo/neurosheaf')

from neurosheaf.sheaf.construction import Sheaf
from neurosheaf.spectral.static_laplacian_unified import UnifiedStaticLaplacian
from neurosheaf.utils.logging import setup_logger

logger = setup_logger(__name__)


def create_demo_sheaf():
    """Create demonstration sheaf with known edge weights."""
    # Create diamond topology: 0 ‚Üí {1,2} ‚Üí 3
    poset = nx.DiGraph()
    poset.add_nodes_from(["A", "B", "C", "D"])
    poset.add_edge("A", "B")
    poset.add_edge("A", "C") 
    poset.add_edge("B", "D")
    poset.add_edge("C", "D")
    
    # Create stalks with moderate dimensions
    stalks = {
        "A": torch.randn(8, 3),
        "B": torch.randn(8, 2),
        "C": torch.randn(8, 2), 
        "D": torch.randn(8, 1)
    }
    
    # Create restrictions with specific known weights for demonstration
    restrictions = {
        ("A", "B"): torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]),     # Weight ‚âà 1.414
        ("A", "C"): torch.tensor([[2.0, 0.0, 0.0], [0.0, 0.0, 1.0]]),     # Weight ‚âà 2.236
        ("B", "D"): torch.tensor([[3.0], [0.0]]),                          # Weight = 3.0
        ("C", "D"): torch.tensor([[0.0], [1.5]])                           # Weight = 1.5
    }
    
    return Sheaf(stalks=stalks, restrictions=restrictions, poset=poset)


def demonstrate_edge_masking():
    """Demonstrate the edge masking functionality."""
    print("üî¨ EDGE MASKING DEMONSTRATION")
    print("=" * 60)
    
    sheaf = create_demo_sheaf()
    unified_laplacian = UnifiedStaticLaplacian(enable_caching=True)
    
    # Get edge information
    static_laplacian, metadata = unified_laplacian._get_or_build_laplacian(sheaf)
    edge_info = unified_laplacian._get_or_extract_edge_info(sheaf, static_laplacian, metadata)
    
    print("üìä SHEAF STRUCTURE:")
    print(f"  Nodes: A, B, C, D (diamond topology)")
    print(f"  Edges: A‚ÜíB, A‚ÜíC, B‚ÜíD, C‚ÜíD")
    print(f"  Laplacian size: {static_laplacian.shape}")
    print(f"  Non-zeros: {static_laplacian.nnz}")
    
    print("\nüìè EDGE WEIGHTS:")
    for edge, info in edge_info.items():
        print(f"  {edge[0]}‚Üí{edge[1]}: {info['weight']:.3f}")
    
    print("\nüéØ FILTRATION DEMONSTRATION:")
    
    # Test different threshold values
    thresholds = [1.0, 1.6, 2.5, 3.5]
    edge_threshold_func = lambda weight, param: weight >= param
    
    for threshold in thresholds:
        print(f"\n  Threshold œÑ = {threshold}")
        
        # Create edge mask
        edge_mask = {edge: info['weight'] >= threshold 
                    for edge, info in edge_info.items()}
        active_edges = [edge for edge, keep in edge_mask.items() if keep]
        
        print(f"    Active edges: {len(active_edges)}")
        for edge in active_edges:
            print(f"      {edge[0]}‚Üí{edge[1]} (weight: {edge_info[edge]['weight']:.3f})")
        
        # Apply masking
        masked_laplacian = unified_laplacian._apply_correct_masking(
            static_laplacian, edge_mask, edge_info, metadata
        )
        
        print(f"    Filtered Laplacian: {masked_laplacian.shape}, {masked_laplacian.nnz} non-zeros")
        
        # Check symmetry
        symmetry_error = abs((masked_laplacian - masked_laplacian.T).max())
        print(f"    Symmetry error: {symmetry_error:.2e}")
        
        # Get eigenvalues for validation
        eigenvals = unified_laplacian._compute_eigenvalues(masked_laplacian)[0]
        min_eigenval = torch.min(eigenvals).item()
        print(f"    Min eigenvalue: {min_eigenval:.6f} (PSD check)")
        print(f"    Eigenvalue count: {len(eigenvals)}")


def performance_benchmark():
    """Benchmark the new masking system performance."""
    print("\n‚ö° PERFORMANCE BENCHMARK")
    print("=" * 60)
    
    sheaf = create_demo_sheaf()
    
    # Test with different configurations
    configs = [
        ("Cached", True),
        ("No Cache", False)
    ]
    
    thresholds = np.linspace(0.5, 3.5, 20).tolist()
    edge_threshold_func = lambda weight, param: weight >= param
    
    print(f"Testing with {len(thresholds)} threshold values...")
    
    for config_name, enable_caching in configs:
        unified_laplacian = UnifiedStaticLaplacian(enable_caching=enable_caching)
        
        start_time = time.time()
        result = unified_laplacian.compute_persistence(sheaf, thresholds, edge_threshold_func)
        computation_time = time.time() - start_time
        
        print(f"\n  {config_name}:")
        print(f"    Computation time: {computation_time:.4f}s")
        print(f"    Time per threshold: {computation_time/len(thresholds):.4f}s")
        print(f"    Eigenvalue sequences: {len(result['eigenvalue_sequences'])}")
        print(f"    Tracking paths: {len(result['tracking_info']['continuous_paths'])}")
        
        if enable_caching:
            cache_info = unified_laplacian.get_cache_info()
            cached_items = sum(cache_info.values())
            print(f"    Cached items: {cached_items}")


def mathematical_validation():
    """Validate mathematical properties of the new system."""
    print("\nüßÆ MATHEMATICAL VALIDATION")
    print("=" * 60)
    
    sheaf = create_demo_sheaf()
    unified_laplacian = UnifiedStaticLaplacian()
    
    # Test filtration with moderate number of steps
    result = unified_laplacian.compute_persistence(
        sheaf, [1.0, 2.0, 3.0], lambda w, p: w >= p
    )
    
    print("üìê LAPLACIAN PROPERTIES:")
    eigenval_sequences = result['eigenvalue_sequences']
    
    for i, eigenvals in enumerate(eigenval_sequences):
        threshold = [1.0, 2.0, 3.0][i]
        
        # Mathematical property checks
        min_eigenval = torch.min(eigenvals).item()
        max_eigenval = torch.max(eigenvals).item()
        eigenval_sum = torch.sum(eigenvals).item()
        
        print(f"\n  Threshold œÑ = {threshold}:")
        print(f"    Eigenvalue count: {len(eigenvals)}")
        print(f"    Range: [{min_eigenval:.6f}, {max_eigenval:.6f}]")
        print(f"    Sum (trace): {eigenval_sum:.6f}")
        print(f"    PSD property: {'‚úÖ' if min_eigenval >= -1e-8 else '‚ùå'}")
        
        # Check for zero eigenvalues (connected components)
        zero_eigenvals = torch.sum(eigenvals < 1e-8).item()
        print(f"    Zero eigenvalues: {zero_eigenvals} (connectivity)")
    
    print("\nüîó PERSISTENCE PROPERTIES:")
    tracking_info = result['tracking_info']
    paths = tracking_info['continuous_paths']
    
    finite_paths = [p for p in paths if p['death_param'] is not None]
    infinite_paths = [p for p in paths if p['death_param'] is None]
    
    print(f"  Continuous paths: {len(paths)}")
    print(f"  Finite paths: {len(finite_paths)}")
    print(f"  Infinite paths: {len(infinite_paths)}")
    
    if finite_paths:
        lifetimes = [p['death_param'] - p['birth_param'] for p in finite_paths]
        print(f"  Average lifetime: {np.mean(lifetimes):.3f}")
        print(f"  Max lifetime: {max(lifetimes):.3f}")


def comparison_demonstration():
    """Demonstrate advantages over old entry-zeroing approach."""
    print("\n‚öñÔ∏è  NEW VS OLD METHOD COMPARISON")
    print("=" * 60)
    
    sheaf = create_demo_sheaf()
    unified_laplacian = UnifiedStaticLaplacian()
    
    # Get static Laplacian and edge info
    static_laplacian, metadata = unified_laplacian._get_or_build_laplacian(sheaf)
    edge_info = unified_laplacian._get_or_extract_edge_info(sheaf, static_laplacian, metadata)
    
    threshold = 2.0
    edge_mask = {edge: info['weight'] >= threshold 
                for edge, info in edge_info.items()}
    
    print(f"Comparison at threshold œÑ = {threshold}")
    print(f"Active edges: {sum(edge_mask.values())}/{len(edge_mask)}")
    
    # NEW METHOD: Block reconstruction
    print("\n‚úÖ NEW METHOD (Block Reconstruction):")
    start_time = time.time()
    new_laplacian = unified_laplacian._apply_correct_masking(
        static_laplacian, edge_mask, edge_info, metadata
    )
    new_time = time.time() - start_time
    
    new_symmetry = abs((new_laplacian - new_laplacian.T).max())
    new_eigenvals = unified_laplacian._compute_eigenvalues(new_laplacian)[0]
    new_min_eigenval = torch.min(new_eigenvals).item()
    
    print(f"  Construction time: {new_time:.6f}s")
    print(f"  Matrix size: {new_laplacian.shape}")
    print(f"  Non-zeros: {new_laplacian.nnz}")
    print(f"  Symmetry error: {new_symmetry:.2e}")
    print(f"  Min eigenvalue: {new_min_eigenval:.6f}")
    print(f"  PSD property: {'‚úÖ' if new_min_eigenval >= -1e-8 else '‚ùå'}")
    
    # SIMULATED OLD METHOD: Entry zeroing (for comparison)
    print("\n‚ùå OLD METHOD (Entry Zeroing - Simulated):")
    old_laplacian = static_laplacian.copy()
    
    # Simulate old method by zeroing entries (mathematically incorrect)
    start_time = time.time()
    for edge, info in edge_info.items():
        if not edge_mask[edge]:  # Edge should be removed
            # This is what the old method incorrectly did
            if hasattr(metadata, 'edge_positions') and edge in metadata.edge_positions:
                positions = metadata.edge_positions[edge]
                for row, col in positions:
                    old_laplacian[row, col] = 0.0
    old_laplacian.eliminate_zeros()
    old_time = time.time() - start_time
    
    old_symmetry = abs((old_laplacian - old_laplacian.T).max()) if old_laplacian.nnz > 0 else 0
    
    print(f"  Construction time: {old_time:.6f}s")
    print(f"  Matrix size: {old_laplacian.shape}")
    print(f"  Non-zeros: {old_laplacian.nnz}")
    print(f"  Symmetry error: {old_symmetry:.2e}")
    print(f"  Mathematical correctness: ‚ùå (destroys Laplacian structure)")
    
    print("\nüèÜ ADVANTAGE SUMMARY:")
    print("  ‚úÖ New method preserves mathematical structure")
    print("  ‚úÖ New method maintains PSD property")
    print("  ‚úÖ New method produces valid persistence diagrams")
    print("  ‚úÖ New method has proper block structure")


def main():
    """Run complete edge masking demonstration."""
    print("LAPLACIAN FILTRATION WITH NEW EDGE MASKING")
    print("COMPREHENSIVE DEMONSTRATION & VALIDATION")
    print("=" * 80)
    
    try:
        demonstrate_edge_masking()
        performance_benchmark()
        mathematical_validation()
        comparison_demonstration()
        
        print("\n" + "=" * 80)
        print("üéâ DEMONSTRATION COMPLETED SUCCESSFULLY!")
        print("‚úÖ New edge masking system validated across all aspects:")
        print("   ‚Ä¢ Mathematical correctness")
        print("   ‚Ä¢ Performance efficiency") 
        print("   ‚Ä¢ Integration with persistence pipeline")
        print("   ‚Ä¢ Advantages over old entry-zeroing approach")
        print("=" * 80)
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Demonstration failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)